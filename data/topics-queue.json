{
  "generatedAt": "2026-02-07T13:49:13.454Z",
  "items": [
    {
      "id": "manual:openclaw-beginner-tutorial",
      "title": "OpenClaw for Beginners: Install, Onboard, and Ship Your First Agent Workflow",
      "link": "https://docs.openclaw.ai/start/wizard",
      "summary": "Beginner tutorial: install OpenClaw, run the onboarding wizard, connect a messaging platform, and ship a safe first workflow with skills + guardrails.",
      "source": "OpenClaw Docs",
      "region": "GLOBAL",
      "keywordHits": 7,
      "publishedAt": "2026-02-07T12:00:00.000Z",
      "score": 999,
      "status": "published",
      "targetRegion": "US",
      "editorialTemplate": "TUTORIAL",
      "publishedAtRun": "2026-02-07T12:31:26.407Z",
      "file": "content/posts/2026-02-07-set-up-openclaw-with-the-cli-onboarding-configure-gateway-seed-workspace-install-a-daemon-and-add-channels.md",
      "fileFr": "content/posts/fr/2026-02-07-set-up-openclaw-with-the-cli-onboarding-configure-gateway-seed-workspace-install-a-daemon-and-add-channels.md",
      "generationMode": "llm",
      "series": "agent-playbook",
      "difficulty": "beginner",
      "timeToImplementMinutes": 60,
      "wordsEn": 1559,
      "wordsFr": 1360
    },
    {
      "id": "https://arxiv.org/abs/2602.04326",
      "title": "From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents",
      "link": "https://arxiv.org/abs/2602.04326",
      "summary": "arXiv:2602.04326v1 Announce Type: new Abstract: Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adapt…",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 9,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 149.89,
      "status": "published",
      "targetRegion": "UK",
      "editorialTemplate": "TUTORIAL",
      "publishedAtRun": "2026-02-07T10:56:37.463Z",
      "file": "content/posts/2026-02-07-pce-converting-llm-reasoning-traces-into-decision-trees-for-uncertainty-aware-planning-in-embodied-multi-agent-tasks.md",
      "fileFr": "content/posts/fr/2026-02-07-pce-converting-llm-reasoning-traces-into-decision-trees-for-uncertainty-aware-planning-in-embodied-multi-agent-tasks.md",
      "generationMode": "llm",
      "series": "agent-playbook",
      "difficulty": "advanced",
      "timeToImplementMinutes": 360,
      "wordsEn": 1480,
      "wordsFr": 1443
    },
    {
      "id": "https://www.lemonde.fr/podcasts/article/2026/02/05/l-intelligence-artificielle-va-t-elle-detruire-nos-emplois_6665446_5463015.html",
      "title": "L’intelligence artificielle va-t-elle détruire nos emplois ?",
      "link": "https://www.lemonde.fr/podcasts/article/2026/02/05/l-intelligence-artificielle-va-t-elle-detruire-nos-emplois_6665446_5463015.html",
      "summary": "Les plans sociaux justifiés par le déploiement de l’IA en entreprise et les déclarations des acteurs du secteur posent question. Dans ce podcast, Alexandre Piquard, journaliste au service Economie du « Monde », fait un point nuancé sur les répercussions qu’a aujourd’hui le déploi",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 0,
      "publishedAt": "2026-02-05T04:00:11.000Z",
      "score": 23.45,
      "status": "published",
      "targetRegion": "FR",
      "editorialTemplate": "NEWS",
      "publishedAtRun": "2026-02-07T09:57:41.567Z",
      "file": "content/posts/2026-02-07-lintelligence-artificielle-va-t-elle-detruire-nos-emplois.md",
      "fileFr": "content/posts/fr/2026-02-07-lintelligence-artificielle-va-t-elle-detruire-nos-emplois.md",
      "generationMode": "llm",
      "series": "model-release-brief",
      "difficulty": "intermediate",
      "timeToImplementMinutes": 5,
      "wordsEn": 1679,
      "wordsFr": 1221
    },
    {
      "id": "https://openai.com/index/unlocking-the-codex-harness",
      "title": "Unlocking the Codex harness: how we built the App Server",
      "link": "https://openai.com/index/unlocking-the-codex-harness",
      "summary": "Learn how to embed the Codex agent using the Codex App Server, a bidirectional JSON-RPC API powering streaming progress, tool use, approvals, and diffs.",
      "source": "OpenAI News",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-04T13:00:00.000Z",
      "score": 12.52,
      "status": "published",
      "targetRegion": "US",
      "editorialTemplate": "TUTORIAL",
      "publishedAtRun": "2026-02-06T18:39:12.939Z",
      "file": "content/posts/2026-02-06-unlocking-the-codex-harness-how-we-built-the-app-server.md",
      "fileFr": "content/posts/fr/2026-02-06-unlocking-the-codex-harness-how-we-built-the-app-server.md",
      "generationMode": "llm",
      "series": "agent-playbook",
      "difficulty": "intermediate",
      "timeToImplementMinutes": 240,
      "wordsEn": 1497,
      "wordsFr": 1300
    },
    {
      "id": "https://www.technologyreview.com/2026/01/28/1131003/rules-fail-at-the-prompt-succeed-at-the-boundary/",
      "title": "Rules fail at the prompt, succeed at the boundary",
      "link": "https://www.technologyreview.com/2026/01/28/1131003/rules-fail-at-the-prompt-succeed-at-the-boundary/",
      "summary": "From the Gemini Calendar prompt-injection attack of 2026 to the September 2025 state-sponsored hack using Anthropic’s Claude code as an automated intrusion engine, the coercion of human-in-the-loop agentic actions and fully autonomous agentic workflows are the new attack vector for hackers. In the Anthropic case, roughly 30 organizations across tech, finance, manufacturing, and government were…",
      "source": "MIT Tech Review AI",
      "region": "US",
      "keywordHits": 5,
      "publishedAt": "2026-01-28T14:00:00.000Z",
      "score": 72.55,
      "status": "published",
      "targetRegion": "UK",
      "editorialTemplate": "TUTORIAL",
      "publishedAtRun": "2026-02-06T16:57:33.586Z",
      "file": "content/posts/2026-02-06-rules-fail-at-the-prompt-succeed-at-the-boundary.md",
      "fileFr": "content/posts/fr/2026-02-06-rules-fail-at-the-prompt-succeed-at-the-boundary.md",
      "wordsEn": 1290,
      "wordsFr": 1521
    },
    {
      "id": "https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl",
      "title": "Unlocking Agentic RL Training for GPT-OSS: A Practical Retrospective",
      "link": "https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl",
      "summary": "",
      "source": "Hugging Face Blog",
      "region": "FR",
      "keywordHits": 2,
      "publishedAt": "2026-01-27T01:53:15.000Z",
      "score": 36.47,
      "status": "published",
      "targetRegion": "FR",
      "editorialTemplate": "NEWS",
      "publishedAtRun": "2026-02-06T15:28:17.709Z",
      "file": "content/posts/2026-02-06-unlocking-agentic-rl-training-for-gpt-oss-a-practical-retrospective.md",
      "fileFr": "content/posts/fr/2026-02-06-unlocking-agentic-rl-training-for-gpt-oss-a-practical-retrospective.md",
      "wordsEn": 1564,
      "wordsFr": 1590
    },
    {
      "id": "https://www.bbc.com/news/articles/ce3edyx74jko?at_medium=RSS&at_campaign=rss",
      "title": "ChatGPT boss ridiculed for online 'tantrum' over rival's Super Bowl ad",
      "link": "https://www.bbc.com/news/articles/ce3edyx74jko?at_medium=RSS&at_campaign=rss",
      "summary": "Commenters said Altman's lengthy post shows \"a nerve was well and truly hit\" by Anthropic's advert.",
      "source": "BBC Technology",
      "region": "UK",
      "keywordHits": 2,
      "publishedAt": "2026-02-05T12:36:32.000Z",
      "score": 28.48,
      "status": "published",
      "targetRegion": "UK",
      "editorialTemplate": "NEWS",
      "publishedAtRun": "2026-02-06T15:24:40.392Z",
      "file": "content/posts/2026-02-06-chatgpt-boss-ridiculed-for-online-tantrum-over-rivals-super-bowl-ad.md",
      "fileFr": "content/posts/fr/2026-02-06-chatgpt-boss-ridiculed-for-online-tantrum-over-rivals-super-bowl-ad.md",
      "wordsEn": 970,
      "wordsFr": 923
    },
    {
      "id": "https://www.bbc.com/news/articles/c9wx2dz2v44o?at_medium=RSS&at_campaign=rss",
      "title": "AI 'slop' is transforming social media - and a backlash is brewing",
      "link": "https://www.bbc.com/news/articles/c9wx2dz2v44o?at_medium=RSS&at_campaign=rss",
      "summary": "Social media has been flooded with fake, AI-generated images and videos. But will the majority of users actually care?",
      "source": "BBC Technology",
      "region": "UK",
      "keywordHits": 0,
      "publishedAt": "2026-02-04T11:29:30.000Z",
      "score": 12.34,
      "status": "published",
      "targetRegion": "UK",
      "editorialTemplate": "NEWS",
      "publishedAtRun": "2026-02-06T15:19:24.319Z",
      "file": "content/posts/2026-02-06-ai-slop-is-transforming-social-media-and-a-backlash-is-brewing.md",
      "fileFr": "content/posts/fr/2026-02-06-ai-slop-is-transforming-social-media-and-a-backlash-is-brewing.md",
      "wordsEn": 973,
      "wordsFr": 924
    },
    {
      "id": "https://openai.com/index/retiring-gpt-4o-and-older-models",
      "title": "Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ChatGPT",
      "link": "https://openai.com/index/retiring-gpt-4o-and-older-models",
      "summary": "On February 13, 2026, alongside the previously announced retirement⁠ of GPT‑5 (Instant, Thinking, and Pro), we will retire GPT‑4o, GPT‑4.1, GPT‑4.1 mini, and OpenAI o4-mini from ChatGPT. In the API, there are no changes at this time.",
      "source": "OpenAI News",
      "region": "US",
      "keywordHits": 2,
      "publishedAt": "2026-01-29T00:00:00.000Z",
      "score": 36.58,
      "status": "published",
      "targetRegion": "US",
      "publishedAtRun": "2026-02-06T15:14:11.915Z",
      "file": "content/posts/2026-02-06-retiring-gpt-4o-gpt-41-gpt-41-mini-and-openai-o4-mini-in-chatgpt.md",
      "fileFr": "content/posts/fr/2026-02-06-retiring-gpt-4o-gpt-41-gpt-41-mini-and-openai-o4-mini-in-chatgpt.md"
    },
    {
      "id": "https://www.lemonde.fr/politique/article/2026/02/05/chatbots-campagnes-augmentees-l-ia-s-immisce-dans-la-politique-francaise_6665450_823448.html",
      "title": "Chatbots, campagnes « augmentées »… l’IA s’immisce dans la politique française",
      "link": "https://www.lemonde.fr/politique/article/2026/02/05/chatbots-campagnes-augmentees-l-ia-s-immisce-dans-la-politique-francaise_6665450_823448.html",
      "summary": "Au-delà de la production de visuels destinés aux réseaux sociaux, les partis intègrent de plus en plus les outils d’intelligence artificielle dans leur stratégie électorale. D’après une enquête, 27 % des personnes interrogées envisagent d’utiliser l’IA pour se renseigner sur les",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 0,
      "publishedAt": "2026-02-05T04:30:00.000Z",
      "score": 33.5,
      "status": "published",
      "targetRegion": "FR",
      "publishedAtRun": "2026-02-06T14:55:49.006Z",
      "file": "content/posts/2026-02-06-chatbots-campagnes-augmentees-lia-simmisce-dans-la-politique-francaise.md",
      "fileFr": "content/posts/fr/2026-02-06-chatbots-campagnes-augmentees-lia-simmisce-dans-la-politique-francaise.md"
    },
    {
      "id": "https://arxiv.org/abs/2602.03950",
      "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation",
      "link": "https://arxiv.org/abs/2602.03950",
      "summary": "arXiv:2602.03950v1 Announce Type: new \nAbstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is e",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 75.6,
      "status": "published",
      "targetRegion": "US",
      "publishedAtRun": "2026-02-06T14:45:15.842Z",
      "file": "content/posts/2026-02-06-enhancing-mathematical-problem-solving-in-llms-through-execution-driven-reasoning-augmentation.md"
    },
    {
      "id": "https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/",
      "title": "This is the most misunderstood graph in AI",
      "link": "https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/",
      "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community h",
      "source": "MIT Tech Review AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-05T10:00:00.000Z",
      "score": 44.5,
      "status": "published",
      "publishedAtRun": "2026-02-06T12:40:42.029Z",
      "file": "content/posts/2026-02-06-this-is-the-most-misunderstood-graph-in-ai.md"
    },
    {
      "id": "https://arxiv.org/abs/2602.04248",
      "title": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search",
      "link": "https://arxiv.org/abs/2602.04248",
      "summary": "arXiv:2602.04248v1 Announce Type: new Abstract: Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-loop framework that transforms stateless search into a continuous, non-parametric learning process. The framework unifies local exploration with global memory optimization through two novel mechanisms: Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) and a Memory Optimization Agent. PE-EMP functions as a reflexive optimizer within the local search, utilizing pairwise feedback to dynamically synthesize adaptive criteria and evolve meta-prompts (system prompts) in real-time. Simultaneously, the Memory Optimization Agent manages a global repository as a dynamic policy prior, employing atomic operations to distill high-quality insights across problems. Extensive evaluations on complex reasoning benchmarks, including AIME25, ARC-AGI-2, and MathArena Apex, demonstrate that Empirical-MCTS significantly outperforms both stateless MCTS strategies and standalone experience-driven agents. T",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 10,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 137.89,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05073",
      "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
      "link": "https://arxiv.org/abs/2602.05073",
      "summary": "arXiv:2602.05073v1 Announce Type: new Abstract: Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ research must shift to realistic settings with interactive agents, and that a new principled framework for agent UQ is needed. This paper presents the first general formulation of agent UQ that subsumes broad classes of existing UQ setups. Under this formulation, we show that prior works implicitly treat LLM UQ as an uncertainty accumulation process, a viewpoint that breaks down for interactive agents in an open world. In contrast, we propose a novel perspective, a conditional uncertainty reduction process, that explicitly models reducible uncertainty over an agent's trajectory by highlighting \"interactivity\" of actions. From this perspective, we outline a conceptual framework to provide actionable guidance for designing UQ in LLM agent setups. Finally, we conclude with practical implications of the agent UQ in frontier LLM development and domain-specific applications, as well as open remaining problems.",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 6,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 132,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05115",
      "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
      "link": "https://arxiv.org/abs/2602.05115",
      "summary": "arXiv:2602.05115v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence. However, existing benchmarks often assume idealized communication between agents, limiting our ability to diagnose whether LLMs can maintain and repair interactions in more realistic, imperfect settings. To close this gap, we present \\textsc{SocialVeil}, a social learning environment that can simulate social interaction under cognitive-difference-induced communication barriers. Grounded in a systematic literature review of communication challenges in human interaction, \\textsc{SocialVeil} introduces three representative types of such disruption, \\emph{semantic vagueness}, \\emph{sociocultural mismatch}, and \\emph{emotional interference}. We also introduce two barrier-aware evaluation metrics, \\emph{unresolved confusion} and \\emph{mutual understanding}, to evaluate interaction quality under impaired communication. Experiments across 720 scenarios and four frontier LLMs show that barriers consistently impair performance, with mutual understanding reduced by over 45\\% on average, and confusion elevated by nearly 50\\%. Human evaluations validate the fidelity of these simulated barriers (ICC$\\approx$0.78, Pearson r$\\approx$0.80). We further demonstrate that adaptation strategies (Repair Instruction and Interactive learn",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 7,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 132,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05110",
      "title": "Understanding LLM Evaluator Behavior: A Structured Multi-Evaluator Framework for Merchant Risk Assessment",
      "link": "https://arxiv.org/abs/2602.05110",
      "summary": "arXiv:2602.05110v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly used as evaluators of reasoning quality, yet their reliability and bias in payments-risk settings remain poorly understood. We introduce a structured multi-evaluator framework for assessing LLM reasoning in Merchant Category Code (MCC)-based merchant risk assessment, combining a five-criterion rubric with Monte-Carlo scoring to evaluate rationale quality and evaluator stability. Five frontier LLMs generate and cross-evaluate MCC risk rationales under attributed and anonymized conditions. To establish a judge-independent reference, we introduce a consensus-deviation metric that eliminates circularity by comparing each judge's score to the mean of all other judges, yielding a theoretically grounded measure of self-evaluation and cross-model deviation. Results reveal substantial heterogeneity: GPT-5.1 and Claude 4.5 Sonnet show negative self-evaluation bias (-0.33, -0.31), while Gemini-2.5 Pro and Grok 4 display positive bias (+0.77, +0.71), with bias attenuating by 25.8 percent under anonymization. Evaluation by 26 payment-industry experts shows LLM judges assign scores averaging +0.46 points above human consensus, and that the negative bias of GPT-5.1 and Claude 4.5 Sonnet reflects closer alignment with human judgment. Ground-truth validation using payment-network data shows four models",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 7,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 126,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05014",
      "title": "DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search",
      "link": "https://arxiv.org/abs/2602.05014",
      "summary": "arXiv:2602.05014v1 Announce Type: new Abstract: With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in open-domain settings, existing agentic search frameworks commonly treat long documents as flat collections of chunks, underutilizing document-native priors such as hierarchical organization and sequential discourse structure. We introduce DeepRead, a structure-aware, multi-turn document reasoning agent that explicitly operationalizes these priors for long-document question answering. DeepRead leverages LLM-based OCR model to convert PDFs into structured Markdown that preserves headings and paragraph boundaries. It then indexes documents at the paragraph level and assigns each paragraph a coordinate-style metadata key encoding its section identity and in-section order. Building on this representation, DeepRead equips the LLM with two complementary tools: a Retrieve tool that localizes relevant paragraphs while exposing their structural coordinates (with lightweight scanning context), and a ReadSection tool that enables contiguous, order-preserving reading within a specified section and paragraph range. Our experiments demonstrate that DeepRead achieves significant improvements over Search-o1-s",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 6,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 120,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05059",
      "title": "Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education",
      "link": "https://arxiv.org/abs/2602.05059",
      "summary": "arXiv:2602.05059v1 Announce Type: new Abstract: Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably they support mathematically rigorous thinking. This study examines the performance of a LLM on two related graph theoretic problems: a solved problem concerning the gracefulness of line graphs and an open problem for which no solution is currently known. We use an eight stage evaluation protocol that reflects authentic mathematical inquiry, including interpretation, exploration, strategy formation, and proof construction. The model performed strongly on the solved problem, producing correct definitions, identifying relevant structures, recalling appropriate results without hallucination, and constructing a valid proof confirmed by a graph theory expert. For the open problem, the model generated coherent interpretations and plausible exploratory strategies but did not advance toward a solution. It did not fabricate results and instead acknowledged uncertainty, which is consistent with the explicit prompting instructions that directed the model to avoid inventing theorems or unsupported claims. These findings indicate that LLMs can support exploration of established material but remain l",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 6,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 120,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05105",
      "title": "GAMMS: Graph based Adversarial Multiagent Modeling Simulator",
      "link": "https://arxiv.org/abs/2602.05105",
      "summary": "arXiv:2602.05105v1 Announce Type: new Abstract: As intelligent systems and multi-agent coordination become increasingly central to real-world applications, there is a growing need for simulation tools that are both scalable and accessible. Existing high-fidelity simulators, while powerful, are often computationally expensive and ill-suited for rapid prototyping or large-scale agent deployments. We present GAMMS (Graph based Adversarial Multiagent Modeling Simulator), a lightweight yet extensible simulation framework designed to support fast development and evaluation of agent behavior in environments that can be represented as graphs. GAMMS emphasizes five core objectives: scalability, ease of use, integration-first architecture, fast visualization feedback, and real-world grounding. It enables efficient simulation of complex domains such as urban road networks and communication systems, supports integration with external tools (e.g., machine learning libraries, planning solvers), and provides built-in visualization with minimal configuration. GAMMS is agnostic to policy type, supporting heuristic, optimization-based, and learning-based agents, including those using large language models. By lowering the barrier to entry for researchers and enabling high-performance simulations on standard hardware, GAMMS facilitates experimentation and innovation in multi-agent systems, autono",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 6,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 120,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05048",
      "title": "MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation",
      "link": "https://arxiv.org/abs/2602.05048",
      "summary": "arXiv:2602.05048v1 Announce Type: new Abstract: Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading to knowledge gaps in joint planning. We consider the problem of discovering optimal interaction strategies for AI agents to actively elicit human inputs in object-driven planning. To this end, we propose Minimal Information Neuro-Symbolic Tree (MINT) to reason about the impact of knowledge gaps and leverage self-play with MINT to optimize the AI agent's elicitation strategies and queries. More precisely, MINT builds a symbolic tree by making propositions of possible human-AI interactions and by consulting a neural planning policy to estimate the uncertainty in planning outcomes caused by remaining knowledge gaps. Finally, we leverage LLM to search and summarize MINT's reasoning process and curate a set of queries to optimally elicit human inputs for best planning performance. By considering a family of extended Markov decision processes with knowledge gaps, we analyze the return guarantee for a given MINT with active human elicitation. Our evaluation on three benchmarks involving unseen/unknown objects of increasing realism shows that MINT-based planning attains near-expert returns b",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 6,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 114,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.04986",
      "title": "Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence",
      "link": "https://arxiv.org/abs/2602.04986",
      "summary": "arXiv:2602.04986v1 Announce Type: new Abstract: We endorse and expand upon Susan Schneider's critique of the linear model of AI progress and introduce two novel concepts: \"familiar intelligence\" and \"strange intelligence\". AI intelligence is likely to be strange intelligence, defying familiar patterns of ability and inability, combining superhuman capacities in some domains with subhuman performance in other domains, and even within domains sometimes combining superhuman insight with surprising errors that few humans would make. We develop and defend a nonlinear model of intelligence on which \"general intelligence\" is not a unified capacity but instead the ability to achieve a broad range of goals in a broad range of environments, in a manner that defies nonarbitrary reduction to a single linear quantity. We conclude with implications for adversarial testing approaches to evaluating AI capacities. If AI is strange intelligence, we should expect that even the most capable systems will sometimes fail in seemingly obvious tasks. On a nonlinear model of AI intelligence, such errors on their own do not demonstrate a system's lack of outstanding general intelligence. Conversely, excellent performance on one type of task, such as an IQ test, cannot warrant assumptions of broad capacities beyond that task domain.",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 4,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 108,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.04284",
      "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning",
      "link": "https://arxiv.org/abs/2602.04284",
      "summary": "arXiv:2602.04284v1 Announce Type: new Abstract: Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are availab",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 5,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 95.89,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05113",
      "title": "Democratic Preference Alignment via Sortition-Weighted RLHF",
      "link": "https://arxiv.org/abs/2602.05113",
      "summary": "arXiv:2602.05113v1 Announce Type: new Abstract: Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic re",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 4,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 90,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05133",
      "title": "CAST-CKT: Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer for Traffic Flow Prediction",
      "link": "https://arxiv.org/abs/2602.05133",
      "summary": "arXiv:2602.05133v1 Announce Type: new Abstract: Traffic prediction in data-scarce, cross-city settings is challenging due to complex nonlinear dynamics and domain shifts. Existing methods often fail to capture traffic's inherent chaotic nature for effective few-shot learning. We propose CAST-CKT, a novel Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer framework. It employs an efficient chaotic analyser to quantify traffic predictability regimes, driving several key innovations: chaos-aware attention for regime-adaptive temporal modelling; adaptive topology learning for dynamic spatial dependencies; and chaotic consistency-based cross-city alignment for knowledge transfer. The framework also provides horizon-specific predictions with uncertainty quantification. Theoretical analysis shows improved generalisation bounds. Extensive experiments on four benchmarks in cross-city few-shot settings show CAST-CKT outperforms state-of-the-art methods by significant margins in MAE and RMSE, while offering interpretable regime analysis. Code is available at https://github.com/afofanah/CAST-CKT.",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 4,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 84,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05143",
      "title": "HugRAG: Hierarchical Causal Knowledge Graph Design for RAG",
      "link": "https://arxiv.org/abs/2602.05143",
      "summary": "arXiv:2602.05143v1 Announce Type: new Abstract: Retrieval augmented generation (RAG) has enhanced large language models by enabling access to external knowledge, with graph-based RAG emerging as a powerful paradigm for structured retrieval and reasoning. However, existing graph-based methods often over-rely on surface-level node matching and lack explicit causal modeling, leading to unfaithful or spurious answers. Prior attempts to incorporate causality are typically limited to local or single-document contexts and also suffer from information isolation that arises from modular graph structures, which hinders scalability and cross-module causal reasoning. To address these challenges, we propose HugRAG, a framework that rethinks knowledge organization for graph-based RAG through causal gating across hierarchical modules. HugRAG explicitly models causal relationships to suppress spurious correlations while enabling scalable reasoning over large-scale knowledge graphs. Extensive experiments demonstrate that HugRAG consistently outperforms competitive graph-based RAG baselines across multiple datasets and evaluation metrics. Our work establishes a principled foundation for structured, scalable, and causally grounded RAG systems.",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 4,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 84,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.05195",
      "title": "Traceable Cross-Source RAG for Chinese Tibetan Medicine Question Answering",
      "link": "https://arxiv.org/abs/2602.05195",
      "summary": "arXiv:2602.05195v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) promises grounded question answering, yet domain settings with multiple heterogeneous knowledge bases (KBs) remain challenging. In Chinese Tibetan medicine, encyclopedia entries are often dense and easy to match, which can dominate retrieval even when classics or clinical papers provide more authoritative evidence. We study a practical setting with three KBs (encyclopedia, classics, and clinical papers) and a 500-query benchmark (cutoff $K{=}5$) covering both single-KB and cross-KB questions. We propose two complementary methods to improve traceability, reduce hallucinations, and enable cross-KB verification. First, DAKS performs KB routing and budgeted retrieval to mitigate density-driven bias and to prioritize authoritative sources when appropriate. Second, we use an alignment graph to guide evidence fusion and coverage-aware packing, improving cross-KB evidence coverage without relying on naive concatenation. All answers are generated by a lightweight generator, \\textsc{openPangu-Embedded-7B}. Experiments show consistent gains in routing quality and cross-KB evidence coverage, with the full system achieving the best CrossEv@5 while maintaining strong faithfulness and citation correctness.",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 3,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 72,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.03974",
      "title": "Active Epistemic Control for Query-Efficient Verified Planning",
      "link": "https://arxiv.org/abs/2602.03974",
      "summary": "arXiv:2602.03974v1 Announce Type: new Abstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \\textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer that integrates model-based belief management with categorical feasibility checks. AEC maintains a strict separation between a \\emph{grounded fact store} used for commitment and a \\emph{belief store} used only for pruning candidate plans. At each step, it either queries the environment to ground an unresolved predicate when uncertainty is high or predictions are ambiguous, or simulates the predicate to filter hypotheses when confidence is sufficient. Final commitment is gated by grounded precondition coverage and an SQ-BCP pullback-style compatibility check, so simulated beliefs affect efficiency but cannot directly certify feasibility. Experiments on ALFWorld and ScienceWorld show that AEC achieves competitive success with fewer replanning rounds than strong LLM-agent baselines.",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 5,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 71.53,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.04213",
      "title": "InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons",
      "link": "https://arxiv.org/abs/2602.04213",
      "summary": "arXiv:2602.04213v1 Announce Type: new Abstract: Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challenging for a layperson when they want to teach the agent new skills. To lower the barrier of teaching AI agents, we propose Interactive Policy Restructuring and Training (InterPReT), which takes user instructions to continually update the policy structure and optimize its parameters to fit user demonstrations. This enables end-users to interactively give instructions and demonstrations, monitor the agent's performance, and review the agent's decision-making strategies. A user study (N=34) on teaching an AI agent to drive in a racing game confirms that our approach yields more robust policies without impairing system usability, compared to a generic imitation learning baseline, when a layperson is responsible for both giving demonstrations and determining when to stop. This shows that our method is more suitable for end-users without much technical background in machine learning to train a dependable policy",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 4,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 65.89,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.03955",
      "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent",
      "link": "https://arxiv.org/abs/2602.03955",
      "summary": "arXiv:2602.03955v1 Announce Type: new \nAbstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes Agent",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 65.6,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.04144",
      "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows",
      "link": "https://arxiv.org/abs/2602.04144",
      "summary": "arXiv:2602.04144v1 Announce Type: new \nAbstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on in",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 65.6,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.03900",
      "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
      "link": "https://arxiv.org/abs/2602.03900",
      "summary": "arXiv:2602.03900v1 Announce Type: new \nAbstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have co",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 55.6,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.03975",
      "title": "Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure",
      "link": "https://arxiv.org/abs/2602.03975",
      "summary": "arXiv:2602.03975v1 Announce Type: new \nAbstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 55.6,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.04089",
      "title": "Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL",
      "link": "https://arxiv.org/abs/2602.04089",
      "summary": "arXiv:2602.04089v1 Announce Type: new \nAbstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inheren",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 55.6,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.04101",
      "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
      "link": "https://arxiv.org/abs/2602.04101",
      "summary": "arXiv:2602.04101v1 Announce Type: new \nAbstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogene",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 55.6,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.04003",
      "title": "When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making",
      "link": "https://arxiv.org/abs/2602.04003",
      "summary": "arXiv:2602.04003v1 Announce Type: new \nAbstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 45.6,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.04210",
      "title": "Steering LLMs via Scalable Interactive Oversight",
      "link": "https://arxiv.org/abs/2602.04210",
      "summary": "arXiv:2602.04210v1 Announce Type: new \nAbstract: As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficie",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 45.6,
      "status": "queued"
    },
    {
      "id": "https://www.technologyreview.com/2026/01/27/1131793/openais-latest-product-lets-you-vibe-code-science/",
      "title": "OpenAI’s latest product lets you vibe code science",
      "link": "https://www.technologyreview.com/2026/01/27/1131793/openais-latest-product-lets-you-vibe-code-science/",
      "summary": "OpenAI just revealed what its new in-house team, OpenAI for Science, has been up to. The firm has released a free LLM-powered tool for scientists called Prism, which embeds ChatGPT in a text editor for writing scientific papers. The idea is to put ChatGPT front and center inside",
      "source": "MIT Tech Review AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-27T18:00:43.000Z",
      "score": 40.51,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.03978",
      "title": "Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning",
      "link": "https://arxiv.org/abs/2602.03978",
      "summary": "arXiv:2602.03978v1 Announce Type: new \nAbstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informativel",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 35.6,
      "status": "queued"
    },
    {
      "id": "https://arxiv.org/abs/2602.04028",
      "title": "Axiomatic Foundations of Counterfactual Explanations",
      "link": "https://arxiv.org/abs/2602.04028",
      "summary": "arXiv:2602.04028v1 Announce Type: new Abstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has been no systematic study of alternative counterfactual types, nor of global counterfactuals that shed light on a system's overall reasoning process. This paper addresses the two gaps by introducing an axiomatic framework built on a set of desirable properties for counterfactual explainers. It proves impossibility theorems showing that no single explainer can satisfy certain axiom combinations simultaneously, and fully characterizes all compatible sets. Representation theorems then establish five one-to-one correspondences between specific subsets of axioms and the families of explainers that satisfy them. Each family gives rise to a distinct type of counterfactual explanation, uncovering five fundamentally different types of counterfactuals. Some of these correspond to local explanations, while others capture global explanations. Finally, the framework situates existing explainers within th",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 2,
      "publishedAt": "2026-02-06T05:00:00.000Z",
      "score": 35.53,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/introducing-openai-frontier",
      "title": "Introducing OpenAI Frontier",
      "link": "https://openai.com/index/introducing-openai-frontier",
      "summary": "OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents with shared context, onboarding, permissions, and governance.",
      "source": "OpenAI News",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-05T06:00:00.000Z",
      "score": 33.91,
      "status": "queued"
    },
    {
      "id": "https://www.numerama.com/tech/2173427-vous-etes-client-bouygues-cest-maintenant-ou-jamais-pour-activer-perplexity-pro-gratuitement.html",
      "title": "Vous êtes client Bouygues ? C’est maintenant ou jamais pour activer Perplexity Pro gratuitement",
      "link": "https://www.numerama.com/tech/2173427-vous-etes-client-bouygues-cest-maintenant-ou-jamais-pour-activer-perplexity-pro-gratuitement.html",
      "summary": "Depuis près d’un an, Bouygues Telecom propose à ses clients un abonnement gratuit à Perplexity Pro. Mais toute bonne chose a une fin : l’accès gratuit à ce LLM se terminera dans quelques jours. L’heure est donc venue, pour certains, de se désabonner… et pour d’autres, de profiter des tout derniers moments pour s’inscrire.",
      "source": "Numerama IA",
      "region": "FR",
      "keywordHits": 2,
      "publishedAt": "2026-02-04T13:56:55.000Z",
      "score": 31.74,
      "status": "queued"
    },
    {
      "id": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/",
      "title": "Advancing AI benchmarking with Game Arena",
      "link": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/",
      "summary": "We’re expanding Game Arena with Poker and Werewolf, while Gemini 3 Pro and Flash top our chess leaderboard.",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-02T17:00:00.000Z",
      "score": 31.31,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/snowflake-partnership",
      "title": "Snowflake and OpenAI partner to bring frontier intelligence to enterprise data",
      "link": "https://openai.com/index/snowflake-partnership",
      "summary": "OpenAI and Snowflake partner in a $200M agreement to bring frontier intelligence into enterprise data, enabling AI agents and insights directly in Snowflake.",
      "source": "OpenAI News",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-02T06:00:00.000Z",
      "score": 31.17,
      "status": "queued"
    },
    {
      "id": "https://blog.google/innovation-and-ai/technology/ai/release-notes-podcast-project-genie/",
      "title": "Hear more about interactive world models in our latest podcast.",
      "link": "https://blog.google/innovation-and-ai/technology/ai/release-notes-podcast-project-genie/",
      "summary": "The latest episode of the Google AI: Release Notes podcast focuses on Genie 3, a real-time, interactive world model. Host Logan Kilpatrick chats with Diego Rivas, Shlomi…",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-29T15:00:00.000Z",
      "score": 30.63,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/inside-our-in-house-data-agent",
      "title": "Inside OpenAI’s in-house data agent",
      "link": "https://openai.com/index/inside-our-in-house-data-agent",
      "summary": "How OpenAI built an in-house AI data agent that uses GPT-5, Codex, and memory to reason over massive datasets and deliver reliable insights in minutes.",
      "source": "OpenAI News",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-29T10:00:00.000Z",
      "score": 30.62,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/taisei",
      "title": "Taisei Corporation shapes the next generation of talent with ChatGPT",
      "link": "https://openai.com/index/taisei",
      "summary": "Taisei Corporation uses ChatGPT Enterprise to support HR-led talent development and scale generative AI across its global construction business.",
      "source": "OpenAI News",
      "region": "US",
      "keywordHits": 2,
      "publishedAt": "2026-01-29T00:00:00.000Z",
      "score": 30.58,
      "status": "queued"
    },
    {
      "id": "https://www.technologyreview.com/2026/01/28/1131835/what-ai-remembers-about-you-is-privacys-next-frontier/",
      "title": "What AI “remembers” about you is privacy’s next frontier",
      "link": "https://www.technologyreview.com/2026/01/28/1131835/what-ai-remembers-about-you-is-privacys-next-frontier/",
      "summary": "The ability to remember you and your preferences is rapidly becoming a big selling point for AI chatbots and agents.  Earlier this month, Google announced Personal Intelligence, a new way for people to interact with the company’s Gemini chatbot that draws on their Gmail, photos,",
      "source": "MIT Tech Review AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-28T14:57:37.000Z",
      "score": 30.56,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/the-next-chapter-for-ai-in-the-eu",
      "title": "The next chapter for AI in the EU",
      "link": "https://openai.com/index/the-next-chapter-for-ai-in-the-eu",
      "summary": "OpenAI launches the EU Economic Blueprint 2.0 with new data, partnerships, and initiatives to accelerate AI adoption, skills, and growth across Europe.",
      "source": "OpenAI News",
      "region": "US",
      "keywordHits": 2,
      "publishedAt": "2026-01-28T01:00:00.000Z",
      "score": 30.52,
      "status": "queued"
    },
    {
      "id": "https://blog.google/products-and-platforms/products/gemini/release-notes-podcast-smokejumpers/",
      "title": "In our latest podcast, hear how the “Smoke Jumpers” team brings Gemini to billions of people.",
      "link": "https://blog.google/products-and-platforms/products/gemini/release-notes-podcast-smokejumpers/",
      "summary": "Bringing Gemini to billions of users requires a massive, coordinated infrastructure effort. In the latest episode of the Google AI: Release Notes podcast, host Logan Kil…",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-27T10:28:00.000Z",
      "score": 30.5,
      "status": "queued"
    },
    {
      "id": "https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face",
      "title": "AssetOpsBench: Bridging the Gap Between AI Agent Benchmarks and Industrial Reality",
      "link": "https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face",
      "summary": "",
      "source": "Hugging Face Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-21T06:25:31.000Z",
      "score": 30.31,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/trusted-access-for-cyber",
      "title": "Introducing Trusted Access for Cyber",
      "link": "https://openai.com/index/trusted-access-for-cyber",
      "summary": "OpenAI introduces Trusted Access for Cyber, a trust-based framework that expands access to frontier cyber capabilities while strengthening safeguards against misuse.",
      "source": "OpenAI News",
      "region": "US",
      "keywordHits": 2,
      "publishedAt": "2026-02-05T10:00:00.000Z",
      "score": 28.08,
      "status": "queued"
    },
    {
      "id": "https://www.numerama.com/sciences/2170347-horloge-de-lapocalypse-2026-il-ne-reste-que-85-secondes-avant-minuit.html",
      "title": "Horloge de l’Apocalypse 2026 : il ne reste que 85 secondes avant minuit",
      "link": "https://www.numerama.com/sciences/2170347-horloge-de-lapocalypse-2026-il-ne-reste-que-85-secondes-avant-minuit.html",
      "summary": "Réglée à 85 secondes de minuit le 27 janvier 2026, l’Horloge de l’Apocalypse n’a jamais été aussi proche du seuil symbolique de la catastrophe, selon le Bulletin of the Atomic Scientists. L’organisation alerte sur l’escalade des rivalités entre grandes puissances, la fragilisation des accords internationaux et les risques conjugués du nucléaire, du climat et de l’intelligence artificielle.",
      "source": "Numerama IA",
      "region": "FR",
      "keywordHits": 2,
      "publishedAt": "2026-01-29T17:33:03.000Z",
      "score": 24.57,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/introducing-gpt-5-3-codex",
      "title": "Introducing GPT-5.3-Codex",
      "link": "https://openai.com/index/introducing-gpt-5-3-codex",
      "summary": "GPT-5.3-Codex is a Codex-native agent that pairs frontier coding performance with general reasoning to support long-horizon, real-world technical work.",
      "source": "OpenAI News",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-05T00:00:00.000Z",
      "score": 23.27,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/gpt-5-3-codex-system-card",
      "title": "GPT-5.3-Codex System Card",
      "link": "https://openai.com/index/gpt-5-3-codex-system-card",
      "summary": "GPT‑5.3-Codex is the most capable agentic coding model to date, combining the frontier coding performance of GPT‑5.2-Codex with the reasoning and professional knowledge capabilities of GPT‑5.2.",
      "source": "OpenAI News",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-05T00:00:00.000Z",
      "score": 23.27,
      "status": "queued"
    },
    {
      "id": "https://www.lemonde.fr/idees/article/2026/02/04/les-etats-unis-parient-sur-une-coordination-active-entre-les-pays-et-les-industries-pour-securiser-toute-la-chaine-de-l-ia_6665426_3232.html",
      "title": "« Les Etats-Unis parient sur une coordination active entre les pays et les industries pour sécuriser toute la chaîne de l’IA »",
      "link": "https://www.lemonde.fr/idees/article/2026/02/04/les-etats-unis-parient-sur-une-coordination-active-entre-les-pays-et-les-industries-pour-securiser-toute-la-chaine-de-l-ia_6665426_3232.html",
      "summary": "Le plus gros pari énergétique de Trump n’est pas le pétrole du Venezuela, mais le discret projet d’alliance internationale visant à sécuriser la chaîne de valeur de l’intelligence artificielle, explique, dans sa chronique, l’experte américaine Sarah Ladislaw.",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 0,
      "publishedAt": "2026-02-04T19:00:01.000Z",
      "score": 22.74,
      "status": "queued"
    },
    {
      "id": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
      "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3’s Top Model",
      "link": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
      "summary": "",
      "source": "Hugging Face Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-04T15:00:40.000Z",
      "score": 22.63,
      "status": "queued"
    },
    {
      "id": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/",
      "title": "From guardrails to governance: A CEO’s guide for securing agentic systems",
      "link": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/",
      "summary": "The previous article in this series, “Rules fail at the prompt, succeed at the boundary,” focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is s",
      "source": "MIT Tech Review AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-04T14:00:00.000Z",
      "score": 22.57,
      "status": "queued"
    },
    {
      "id": "https://huggingface.co/blog/Photoroom/prx-part2",
      "title": "Training Design for Text-to-Image Models: Lessons from Ablations",
      "link": "https://huggingface.co/blog/Photoroom/prx-part2",
      "summary": "",
      "source": "Hugging Face Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-03T11:25:53.000Z",
      "score": 21.64,
      "status": "queued"
    },
    {
      "id": "https://www.lemonde.fr/societe/article/2026/02/03/laisser-l-ia-hors-de-la-classe-c-est-la-laisser-sans-contre-pouvoir_6665166_3224.html",
      "title": "« Laisser l’IA hors de la classe, c’est la laisser sans contre‑pouvoir »",
      "link": "https://www.lemonde.fr/societe/article/2026/02/03/laisser-l-ia-hors-de-la-classe-c-est-la-laisser-sans-contre-pouvoir_6665166_3224.html",
      "summary": "Docteur en histoire et professeur dans le secondaire, Nicolas Smaghue plaide, dans une tribune au « Monde », pour une « voie médiane » concernant l’utilisation de l’intelligence artificielle à l’école, refusant une « abstinence générale ».",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 0,
      "publishedAt": "2026-02-03T05:00:09.000Z",
      "score": 21.47,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/introducing-the-codex-app",
      "title": "Introducing the Codex app",
      "link": "https://openai.com/index/introducing-the-codex-app",
      "summary": "Introducing the Codex app for macOS—a command center for AI coding and software development with multiple agents, parallel workflows, and long-running tasks.",
      "source": "OpenAI News",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-02T00:00:00.000Z",
      "score": 21.1,
      "status": "queued"
    },
    {
      "id": "https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/",
      "title": "Inside the marketplace powering bespoke AI deepfakes of real women",
      "link": "https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/",
      "summary": "Civitai—an online marketplace for buying and selling AI-generated content, backed by the venture capital firm Andreessen Horowitz—is letting users buy custom instruction files for generating celebrity deepfakes. Some of these files were specifically designed to make pornographic",
      "source": "MIT Tech Review AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-30T16:32:31.000Z",
      "score": 20.73,
      "status": "queued"
    },
    {
      "id": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/dear-upstairs-neighbors/",
      "title": "How animators and AI researchers made ‘Dear Upstairs Neighbors’",
      "link": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/dear-upstairs-neighbors/",
      "summary": "Today, our animated short film, “Dear Upstairs Neighbors,” previews at the Sundance Film Festival.",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-26T18:00:00.000Z",
      "score": 20.46,
      "status": "queued"
    },
    {
      "id": "https://blog.google/company-news/outreach-and-initiatives/accessibility/natively-adaptive-interfaces-ai-accessibility/",
      "title": "Natively Adaptive Interfaces: A new framework for AI accessibility",
      "link": "https://blog.google/company-news/outreach-and-initiatives/accessibility/natively-adaptive-interfaces-ai-accessibility/",
      "summary": "Learn how Google's NAI framework uses AI to make technology more adaptive, inclusive and helpful for everyone.",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-05T17:00:00.000Z",
      "score": 16.1,
      "status": "queued"
    },
    {
      "id": "https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/us-ski-snowboard-tool-winter-olympics-2026/",
      "title": "How Google Cloud is helping Team USA elevate their tricks with AI",
      "link": "https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/us-ski-snowboard-tool-winter-olympics-2026/",
      "summary": "Google Cloud built an industry-first AI tool to help U.S. Ski and Snowboard athletes.",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-05T16:00:00.000Z",
      "score": 15.8,
      "status": "queued"
    },
    {
      "id": "https://blog.google/innovation-and-ai/products/google-ai-updates-january-2026/",
      "title": "The latest AI news we announced in January",
      "link": "https://blog.google/innovation-and-ai/products/google-ai-updates-january-2026/",
      "summary": "Google AI announcements from January",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-04T16:55:00.000Z",
      "score": 12.74,
      "status": "queued"
    },
    {
      "id": "https://www.lemonde.fr/m-le-mag/article/2026/02/04/lolita-cercel-la-chanteuse-creee-par-ia-en-roumanie-fascine-et-inquiete_6665414_4500055.html",
      "title": "Lolita Cercel, la chanteuse créée par IA en Roumanie, fascine et inquiète",
      "link": "https://www.lemonde.fr/m-le-mag/article/2026/02/04/lolita-cercel-la-chanteuse-creee-par-ia-en-roumanie-fascine-et-inquiete_6665414_4500055.html",
      "summary": "L’artiste virtuelle créée par l’intelligence artificielle cumule des milliers de vues et d’écoutes sur les plateformes en Roumanie, bousculant les milieux artistiques.",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 0,
      "publishedAt": "2026-02-04T17:30:02.000Z",
      "score": 12.65,
      "status": "queued"
    },
    {
      "id": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
      "title": "H Company's new Holo2 model takes the lead in UI Localization",
      "link": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
      "summary": "",
      "source": "Hugging Face Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-03T17:40:14.000Z",
      "score": 11.79,
      "status": "queued"
    },
    {
      "id": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3",
      "title": "The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+",
      "link": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3",
      "summary": "",
      "source": "Hugging Face Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-03T15:03:19.000Z",
      "score": 11.72,
      "status": "queued"
    },
    {
      "id": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
      "title": "What we’ve been getting wrong about AI’s truth crisis",
      "link": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
      "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. What would it take to convince you that the era of truth decay we were long warned about—where AI content dupes us, shapes our beliefs even wh",
      "source": "MIT Tech Review AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-02T18:09:57.000Z",
      "score": 11.33,
      "status": "queued"
    },
    {
      "id": "https://blog.google/innovation-and-ai/technology/ai/ai-to-preserve-endangered-species/",
      "title": "How we’re helping preserve the genetic information of endangered species with AI",
      "link": "https://blog.google/innovation-and-ai/technology/ai/ai-to-preserve-endangered-species/",
      "summary": "Scientists are working to sequence the genome of every known species on Earth.",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-02T18:00:00.000Z",
      "score": 11.32,
      "status": "queued"
    },
    {
      "id": "https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/",
      "title": "The crucial first step for designing a successful enterprise AI system",
      "link": "https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/",
      "summary": "Many organizations rushed into generative AI, only to see pilots fail to deliver value. Now, companies want measurable outcomes—but how do you design for success? At Mistral AI, we partner with global industry leaders to co-design tailored AI solutions that solve their most diffi",
      "source": "MIT Tech Review AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-02-02T14:20:29.000Z",
      "score": 11.27,
      "status": "queued"
    },
    {
      "id": "https://www.technologyreview.com/2026/01/29/1131787/the-ai-hype-index-grok-makes-porn-claude-code-nails-your-job/",
      "title": "The AI Hype Index: Grok makes porn, and Claude Code nails your job",
      "link": "https://www.technologyreview.com/2026/01/29/1131787/the-ai-hype-index-grok-makes-porn-claude-code-nails-your-job/",
      "summary": "Everyone is panicking because AI is very bad; everyone is panicking because AI is very good. It’s just that you never know which one you’re going to get. Grok is a pornography machine. Claude Code can do anything from building websites to reading your MRI. So of course Gen Z is s",
      "source": "MIT Tech Review AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-29T20:56:23.000Z",
      "score": 10.65,
      "status": "queued"
    },
    {
      "id": "https://www.technologyreview.com/2026/01/29/1131938/dhs-is-using-google-and-adobe-ai-to-make-videos/",
      "title": "DHS is using Google and Adobe AI to make videos",
      "link": "https://www.technologyreview.com/2026/01/29/1131938/dhs-is-using-google-and-adobe-ai-to-make-videos/",
      "summary": "The US Department of Homeland Security is using AI video generators from Google and Adobe to make and edit content shared with the public, a new document reveals. It comes as immigration agencies have flooded social media with content to support President Trump’s mass deportation",
      "source": "MIT Tech Review AI",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-29T18:57:11.000Z",
      "score": 10.65,
      "status": "queued"
    },
    {
      "id": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/",
      "title": "Project Genie: Experimenting with infinite, interactive worlds",
      "link": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/",
      "summary": "Google AI Ultra subscribers in the U.S. can now try out Project Genie.",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-29T17:00:00.000Z",
      "score": 10.64,
      "status": "queued"
    },
    {
      "id": "https://huggingface.co/blog/upskill",
      "title": "We Got Claude to Build CUDA Kernels and teach open models!",
      "link": "https://huggingface.co/blog/upskill",
      "summary": "",
      "source": "Hugging Face Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-28T00:00:00.000Z",
      "score": 10.52,
      "status": "queued"
    },
    {
      "id": "https://blog.google/products-and-platforms/products/google-one/google-ai-plus-availability/",
      "title": "Google AI Plus is now available everywhere our AI plans are available, including the U.S.",
      "link": "https://blog.google/products-and-platforms/products/google-one/google-ai-plus-availability/",
      "summary": "We’re launching Google AI Plus in 35 new countries and territories including the US, making it available everywhere Google AI plans are available.",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-27T18:00:00.000Z",
      "score": 10.51,
      "status": "queued"
    },
    {
      "id": "https://blog.google/products-and-platforms/products/search/ai-mode-ai-overviews-updates/",
      "title": "Just ask anything: a seamless new Search experience",
      "link": "https://blog.google/products-and-platforms/products/search/ai-mode-ai-overviews-updates/",
      "summary": "Search users around the world now have easier access to frontier AI capabilities.",
      "source": "Google AI Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-27T17:00:00.000Z",
      "score": 10.51,
      "status": "queued"
    },
    {
      "id": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2",
      "title": "Architectural Choices in China's Open-Source AI Ecosystem: Building Beyond DeepSeek",
      "link": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2",
      "summary": "",
      "source": "Hugging Face Blog",
      "region": "GLOBAL",
      "keywordHits": 0,
      "publishedAt": "2026-01-27T15:01:45.000Z",
      "score": 10.5,
      "status": "queued"
    },
    {
      "id": "https://openai.com/index/gpt-5-lowers-protein-synthesis-cost",
      "title": "GPT-5 lowers the cost of cell-free protein synthesis",
      "link": "https://openai.com/index/gpt-5-lowers-protein-synthesis-cost",
      "summary": "An autonomous lab combining OpenAI’s GPT-5 with Ginkgo Bioworks’ cloud automation cut cell-free protein synthesis costs by 40% through closed-loop experimentation.",
      "source": "OpenAI News",
      "region": "US",
      "keywordHits": 3,
      "publishedAt": "2026-02-05T11:00:00.000Z",
      "score": 40.22,
      "status": "failed",
      "targetRegion": "US",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T10:50:58.503Z",
      "failureReason": "insufficient source snapshots (0/1)"
    },
    {
      "id": "https://arxiv.org/abs/2602.05088",
      "title": "VERA-MH: Reliability and Validity of an Open-Source AI Safety Evaluation in Mental Health",
      "link": "https://arxiv.org/abs/2602.05088",
      "summary": "arXiv:2602.05088v1 Announce Type: new Abstract: Millions now use leading generative AI chatbots for psychological support. Despite the promise related to availability and scale, the single most pressing question in AI for mental health is whether these tools are safe. The Validation of Ethical and Responsible AI in Mental Health (VERA-MH) evaluation was recently proposed to meet the urgent need for an evidence-based…",
      "source": "ArXiv cs.AI",
      "region": "GLOBAL",
      "keywordHits": 9,
      "publishedAt": "2026-02-07T05:00:00.000Z",
      "score": 150,
      "status": "failed",
      "targetRegion": "UK",
      "editorialTemplate": "TUTORIAL",
      "failedAtRun": "2026-02-07T10:43:13.225Z",
      "failureReason": "insufficient source snapshots (1/2)"
    },
    {
      "id": "https://www.numerama.com/tech/2161859-quest-ce-quun-llm-large-language-model-et-comment-cela-fonctionne.html",
      "title": "Qu’est-ce qu’un LLM (Large Language Model) et comment cela fonctionne ?",
      "link": "https://www.numerama.com/tech/2161859-quest-ce-quun-llm-large-language-model-et-comment-cela-fonctionne.html",
      "summary": "L’intelligence artificielle a pris un autre tournant avec les LLM. ChatGPT, Gemini ou encore Claude, ces LLM sont désormais des outils incontournables et ont changé notre manière d’interagir avec la machine.",
      "source": "Numerama IA",
      "region": "FR",
      "keywordHits": 5,
      "publishedAt": "2026-01-24T17:31:00.000Z",
      "score": 72.36,
      "status": "failed",
      "targetRegion": "FR",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T10:43:13.225Z",
      "failureReason": "insufficient source bundle (need at least 2 URLs)"
    },
    {
      "id": "https://openai.com/index/our-approach-to-localization",
      "title": "Making AI work for everyone, everywhere: our approach to localization",
      "link": "https://openai.com/index/our-approach-to-localization",
      "summary": "OpenAI shares its approach to AI localization, showing how globally shared frontier models can be adapted to local languages, laws, and cultures without compromising safety.",
      "source": "OpenAI News",
      "region": "US",
      "keywordHits": 4,
      "publishedAt": "2026-02-06T10:00:00.000Z",
      "score": 59.37,
      "status": "failed",
      "targetRegion": "US",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T10:43:13.225Z",
      "failureReason": "insufficient source bundle (need at least 2 URLs)"
    },
    {
      "id": "https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/",
      "title": "Moltbook was peak AI theater",
      "link": "https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/",
      "summary": "For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website’s tagline puts it: “Where AI agents share, discuss, and upvote. Humans welcome to observe.” We observed! Launched on January 28 by Matt Schlicht,…",
      "source": "MIT Tech Review AI",
      "region": "US",
      "keywordHits": 3,
      "publishedAt": "2026-02-06T16:38:11.000Z",
      "score": 49.64,
      "status": "failed",
      "targetRegion": "US",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T10:43:13.225Z",
      "failureReason": "insufficient source bundle (need at least 2 URLs)"
    },
    {
      "id": "https://www.bbc.com/news/articles/c62n410w5yno?at_medium=RSS&at_campaign=rss",
      "title": "What is the 'social media network for AI' Moltbook?",
      "link": "https://www.bbc.com/news/articles/c62n410w5yno?at_medium=RSS&at_campaign=rss",
      "summary": "The Reddit-like website which launched in late January allows AI bots to speak to each other.",
      "source": "BBC Technology",
      "region": "UK",
      "keywordHits": 0,
      "publishedAt": "2026-02-02T13:59:14.000Z",
      "score": 11.24,
      "status": "failed",
      "targetRegion": "UK",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T10:43:13.225Z",
      "failureReason": "insufficient source bundle (need at least 2 URLs)"
    },
    {
      "id": "https://www.lemonde.fr/economie/article/2026/02/03/fusion-spacex-xai-elon-musk-defend-son-projet-d-ia-dans-l-espace-les-analystes-s-interrogent-sur-la-viabilite-de-l-ensemble_6665163_3234.html",
      "title": "Fusion SpaceX-xAI : Elon Musk défend son projet d’IA dans l’espace, les analystes s’interrogent sur la viabilité de l’ensemble",
      "link": "https://www.lemonde.fr/economie/article/2026/02/03/fusion-spacex-xai-elon-musk-defend-son-projet-d-ia-dans-l-espace-les-analystes-s-interrogent-sur-la-viabilite-de-l-ensemble_6665163_3234.html",
      "summary": "Le rapprochement entre les deux entités va donner naissance à la société non cotée la plus chère du monde, valorisée 1 250 milliards de dollars. Son patron, à la traîne dans l’intelligence artificielle, espère rattraper les leaders du secteur.",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 2,
      "publishedAt": "2026-02-03T04:34:27.000Z",
      "score": 31.45,
      "status": "failed",
      "targetRegion": "FR",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T08:20:00.214Z",
      "failureReason": "strict publish refused generationMode=\"fallback\""
    },
    {
      "id": "https://www.lemonde.fr/economie/article/2026/02/03/elon-musk-fusionne-xai-et-spacex-pour-batir-des-centres-de-donnees-en-orbite_6665150_3234.html",
      "title": "Elon Musk fusionne xAI et SpaceX pour bâtir des centres de données en orbite",
      "link": "https://www.lemonde.fr/economie/article/2026/02/03/elon-musk-fusionne-xai-et-spacex-pour-batir-des-centres-de-donnees-en-orbite_6665150_3234.html",
      "summary": "L’intégration de la société d’intelligence artificielle du milliardaire américain précède le projet d’introduction en Bourse de l’entreprise spatiale cette année.",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 2,
      "publishedAt": "2026-02-02T23:24:09.000Z",
      "score": 31.37,
      "status": "failed",
      "targetRegion": "FR",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T08:20:00.214Z",
      "failureReason": "strict publish refused generationMode=\"fallback\""
    },
    {
      "id": "https://www.lemonde.fr/economie/video/2026/02/02/friend-com-que-vendent-ces-publicites-affichees-dans-le-metro-parisien_6665132_3234.html",
      "title": "Friend.com : que vendent ces publicités affichées dans le métro parisien ?",
      "link": "https://www.lemonde.fr/economie/video/2026/02/02/friend-com-que-vendent-ces-publicites-affichees-dans-le-metro-parisien_6665132_3234.html",
      "summary": "Ces affiches publicitaires blanches aux slogans énigmatiques ont interrogé de nombreux internautes sur les réseaux sociaux. Il s’agit d’un collier permettant de discuter avec une intelligence artificielle en continu.",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 2,
      "publishedAt": "2026-02-02T17:44:34.000Z",
      "score": 25.29,
      "status": "failed",
      "targetRegion": "FR",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T08:20:00.214Z",
      "failureReason": "strict publish refused generationMode=\"fallback\""
    },
    {
      "id": "https://www.lemonde.fr/emploi/article/2026/02/02/recrutement-peut-on-maitriser-les-secrets-des-algorithmes-avant-de-postuler_6665057_1698637.html",
      "title": "Recrutement : peut-on maîtriser les secrets des algorithmes avant de postuler ?",
      "link": "https://www.lemonde.fr/emploi/article/2026/02/02/recrutement-peut-on-maitriser-les-secrets-des-algorithmes-avant-de-postuler_6665057_1698637.html",
      "summary": "Pour faire face aux afflux de candidats, 80 % des entreprises françaises utilisent ou envisagent d’utiliser un Applicant Tracking System (ATS), logiciel de gestion des profils. Pour maximiser ses chances, on peut tenter d’en maîtriser les codes, avec certaines limites.",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 2,
      "publishedAt": "2026-02-02T05:30:04.000Z",
      "score": 25.14,
      "status": "failed",
      "targetRegion": "FR",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T08:20:00.214Z",
      "failureReason": "strict publish refused generationMode=\"fallback\""
    },
    {
      "id": "https://www.lemonde.fr/economie/article/2026/02/05/les-craintes-sur-l-ia-font-plonger-la-tech-a-wall-street_6665487_3234.html",
      "title": "Les craintes sur l’IA font plonger la tech à Wall Street",
      "link": "https://www.lemonde.fr/economie/article/2026/02/05/les-craintes-sur-l-ia-font-plonger-la-tech-a-wall-street_6665487_3234.html",
      "summary": "Malgré des résultats supérieurs aux attentes, Alphabet, maison mère de Google, a été puni en Bourse, mercredi, pour avoir annoncé des investissements massifs dans l’IA. Les marchés semblent avoir pris conscience des risques de l’intelligence artificielle pour les entreprises.",
      "source": "Le Monde IA",
      "region": "FR",
      "keywordHits": 0,
      "publishedAt": "2026-02-05T08:08:31.000Z",
      "score": 23.92,
      "status": "failed",
      "targetRegion": "FR",
      "editorialTemplate": "NEWS",
      "failedAtRun": "2026-02-07T08:20:00.214Z",
      "failureReason": "strict publish refused generationMode=\"fallback\""
    }
  ]
}